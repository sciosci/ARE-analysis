{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, os\n",
    "from os import listdir\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pubmed_parser as pp\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import textstat\n",
    "from matplotlib.colors import is_color_like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "stop = set(stopwords.words('english') + list(string.punctuation))\n",
    "alphabet = list(string.ascii_lowercase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yolo_result(result):\n",
    "    ans = []\n",
    "    \n",
    "    for i in range(len(result)-1):\n",
    "        if 'Predicted in' in result[i]:\n",
    "            file = result[i].split(': ')[0].split('/')[-1]\n",
    "            if 'Predicted in' in result[i+1]:\n",
    "                ans.append([file, 0])\n",
    "            else:\n",
    "                for j in range(2, 20):\n",
    "                    if  i+j < len(result)-1 and 'Predicted in' in result[i+j]:\n",
    "                        idx = j\n",
    "                        break\n",
    "                    elif i+j >= len(result)-1:\n",
    "                        idx = j\n",
    "                        break\n",
    "                conf = 0\n",
    "                for line in result[i+1:i+j]:\n",
    "                    conf = max(conf, int(line.split(': ')[1].split('%')[0]))\n",
    "                ans.append([file, conf])\n",
    "    if 'Predicted in' in result[-1]:\n",
    "        ans.append([result[-1].split(': ')[0].split('/')[-1], 0])\n",
    "        \n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_path = '//'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def caption(pmcid):\n",
    "    tmp = [x for x in listdir(xml_path+pmcid+'/') if x[-5:] == '.nxml']\n",
    "    if len(tmp) == 1:\n",
    "        nxml_path = xml_path+pmcid+'/'+tmp[0]\n",
    "    else:\n",
    "        print(len(tmp))\n",
    "        print(pmcid)\n",
    "    return pp.parse_pubmed_caption(nxml_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_float(s):\n",
    "    try:\n",
    "        float(s)\n",
    "    except:\n",
    "        return(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbol = ['trinagle', 'circle', 'square', 'diamond', 'trinagles', 'circles', 'squares', 'diamonds', '▪', '□', \n",
    "          'dashed', 'hatched']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_count(text_list):\n",
    "    c = 0\n",
    "    for i in range(len(text_list)):\n",
    "        if is_color_like(check_float(text_list[i])) or text_list[i] in symbol:\n",
    "            c += 1\n",
    "        if text_list[-1] != 'solid':\n",
    "            if text_list[i] == 'solid' and text_list[i+1] in ['line', 'lines']:\n",
    "                c += 1\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(path):\n",
    "    img = mpimg.imread(path)\n",
    "    imgplot = plt.imshow(img)\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Legend detection on subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darknet = './darknet'\n",
    "current = os.path.abspath(os.getcwd())\n",
    "voc = current+'/data/legend.data'\n",
    "cfg = current+'/data/yolov4_legend.cfg'\n",
    "weights = current+'/yolov4_legend_last.weights'\n",
    "subplot_list = current+'/yolo_detection_all/subplot_list.txt'\n",
    "subplot_result = current+'/yolo_detection_all/subplot_legend_result.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write figure path\n",
    "subplot_folder_path = './line_charts/all/'\n",
    "figure_path = listdir(subplot_folder_path)\n",
    "f = open(subplot_list):\n",
    "for ff in figure_path:\n",
    "    f.write(subplot_folder_path+ff+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subplot_legend_command = darknet+' detector test '+voc+' '+cfg+' '+weights+' '+ \\\n",
    "        '-dont_show -ext_output < ' +subplot_list+ ' > '+subplot_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = subprocess.Popen(subplot_legend_command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, \n",
    "                     cwd='./darknet', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting result and wirte into dataframe\n",
    "f = open(subplot_result, \"r\")\n",
    "subplot_legend_detection = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subplot_legend_detection = [x for x in subplot_legend_detection if 'Predicted in' in x or 'Legend' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(get_yolo_result(subplot_legend_detection), columns = ['File', 'Legend'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Legend detection on Compound (Original) figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get corresponding compound figures of subplots\n",
    "compound = []\n",
    "compound_path = '//'\n",
    "for f in figure_path:\n",
    "    if f[-6] == '_':\n",
    "        if exists(compound_path+f[:-6]+'.png'):\n",
    "            compound.append(compound_path+f[:-6]+'.png')\n",
    "        elif exists(compound_path+f[:-6]+'.jpg'):\n",
    "            compound.append(compound_path+f[:-6]+'.jpg')\n",
    "    elif f[-7] == '_':\n",
    "        if exists(compound_path+f[:-7+'.png'):\n",
    "            compound.append(compound_path+f[:-7]+'.png')\n",
    "        elif exists(compound_path+f[:-7]+'.jpg'):\n",
    "            compound.append(compound_path+f[:-7]+'.jpg')      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "darknet = './darknet'\n",
    "current = os.path.abspath(os.getcwd())\n",
    "voc = current+'/data/legend.data'\n",
    "cfg = current+'/data/yolov4_legend.cfg'\n",
    "weights = current+'/yolov4_legend_last.weights'\n",
    "compound_list = current+'/yolo_detection_all/compound_list.txt'\n",
    "compound_result = current+'/yolo_detection_all/compound_result.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(compound_list, \"w\")\n",
    "for ff in compound:\n",
    "    f.write(ff+'\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_legend_command = darknet+' detector test '+voc+' '+cfg+' '+weights+' '+ \\\n",
    "        '-dont_show -ext_output < ' +compound_list+ ' > '+compound_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = subprocess.Popen(compound_legend_command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, \n",
    "                     cwd='./darknet', shell=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p.communicate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(compound_result, \"r\")\n",
    "compound_legend_detection = f.readlines()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_legend_detection=[x for x in compound_legend_detection if 'Predicted in' in x or 'Legend' in x]\n",
    "compound_dict = dict(get_yolo_result(compound_legend_detection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine subplot and compound legend detection result\n",
    "for i in range(len(df)):\n",
    "    tmp_f = df.loc[i, 'File']\n",
    "    if tmp_f[:-6] + '.png' in compound_dict:\n",
    "        df.loc[i, 'Original'] = compound_dict[tmp_f[:-6] + '.png']\n",
    "    elif tmp_f[:-6] + '.jpg' in compound_dict:\n",
    "        df.loc[i, 'Original'] = compound_dict[tmp_f[:-6] + '.jpg']\n",
    "    elif tmp_f[:-7] + '.png' in compound_dict:\n",
    "        df.loc[i, 'Original'] = compound_dict[tmp_f[:-7] + '.png']\n",
    "    elif tmp_f[:-7] + '.jpg' in compound_dict:\n",
    "        df.loc[i, 'Original'] = compound_dict[tmp_f[:-7] + '.jpg']\n",
    "    else:\n",
    "        df.loc[i, 'Original'] = -1\n",
    "        print(tmp_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify if a graph need legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet_v2 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.keras.preprocessing.image_dataset_from_directory('./line_charts/', batch_size=4, image_size=(224,224))\n",
    "file_name = [x.split('/')[-1] for x in dataset.file_paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend_classifier = tf.keras.models.load_model('need_legend_classifier/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = legend_classifier.predict(dataset)\n",
    "predictions = tf.nn.sigmoid(predictions)\n",
    "predictions = np.array(tf.where(predictions < 0.5, 0, 1))\n",
    "pred_list = [x[0] for x in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "need_legend_df = pd.DataFrame({'File':file_name, 'need_legend':pred_list})\n",
    "df = df.merge(need_legend_df, left_on='File', right_on='File')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caption Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_names, color_rgb = primary_colors('Base Colors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(df)):\n",
    "    f = df.loc[j, 'File']\n",
    "    # caption analysis\n",
    "    pmcid = f.split('_')[0]\n",
    "    try:\n",
    "        tmp_caption = caption(pmcid)\n",
    "        for i in range(len(tmp_caption)):\n",
    "            if tmp_caption[i]['graphic_ref'] == '_'.join(f.split('_')[1:-1]) or \\\n",
    "                tmp_caption[i]['graphic_ref'] == '_'.join(f.split('_')[1:])[:-4]:\n",
    "                text = tmp_caption[i]['fig_caption']\n",
    "                text_index = textstat.automated_readability_index(text)\n",
    "                text_list = [i for i in word_tokenize(text.lower()) if i not in stop and i not in alphabet]\n",
    "                color_index = color_count(text_list)\n",
    "                df.loc[j, ['read_index', 'explain_count']] = [text_index, color_index]\n",
    "                \n",
    "    except:\n",
    "        df.loc[j, ['read_index', 'explain_count']] = [-1, -1]\n",
    "        print(pmcid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
